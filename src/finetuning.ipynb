{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PreTrainedTokenizerFast, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer\n",
    "import evaluate\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaForSequenceClassification, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "VAL_DATASET_LENGTH = 200\n",
    "USE_SMALL_DATASET = True\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['qid', 'term', 'description', 'question', 'answer'],\n",
      "        num_rows: 2821\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['qid', 'term', 'description', 'question', 'answer'],\n",
      "        num_rows: 490\n",
      "    })\n",
      "})\n",
      "{'qid': '872', 'term': 'Swastika', 'description': 'a geometrical figure and an ancient religious icon in the cultures of Eurasia and 20th-century symbol of Nazism', 'question': 'Did the Hopi Indians use a symbol that was similar to the swastika?', 'answer': True}\n",
      "Did the Hopi Indians use a symbol that was similar to the swastika?\n",
      "True\n",
      "{'qid': '564959490dd0b8316a88', 'term': None, 'description': None, 'question': 'can you use Microsoft Office without internet?', 'answer': None}\n",
      "can you use Microsoft Office without internet?\n"
     ]
    }
   ],
   "source": [
    "# load dataset from datasets/strategyqa_train_filtered.json\n",
    "dataset = load_dataset(\"json\", data_files={\"train\": \"../datasets/strategyqa_train_filtered.json\", \"test\": \"../datasets/strategyqa_test.json\"})\n",
    "print(dataset)\n",
    "# initialize training, validation, and testing dataset\n",
    "train_dataset = dataset['train'].select(indices=range(len(dataset['train']) - VAL_DATASET_LENGTH))\n",
    "val_dataset = dataset['train'].select(indices=range(len(dataset['train']) - VAL_DATASET_LENGTH, len(dataset['train'])))\n",
    "test_dataset = dataset['test']\n",
    "if USE_SMALL_DATASET:\n",
    "    train_dataset = train_dataset.select(range(100)) # we use the first 100 entries to test the code\n",
    "    val_dataset = val_dataset.select(range(100)) # we use the first 100 entries to test the code\n",
    "    test_dataset = test_dataset.select(range(100)) # we use the first 100 entries to test the code\n",
    "print(dataset['train'][0])\n",
    "print(dataset['train'][0]['question'])\n",
    "print(dataset['train'][0]['answer'])\n",
    "print(dataset['test'][0])\n",
    "print(dataset['test'][0]['question'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 4111.66 examples/s]\n",
      "Map: 100%|██████████| 100/100 [00:00<00:00, 5262.81 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# tokenize the dataset\n",
    "def tokenize_function(batch, tokenizer=tokenizer, field_name=\"question\"):\n",
    "    return tokenizer(batch[field_name], padding=\"max_length\", truncation=True)\n",
    "\n",
    "    \n",
    "def add_labels(tokenized_dataset):\n",
    "    tokenized_dataset[\"labels\"] = 1 if tokenized_dataset[\"answer\"] else 0 # Assuming \"answer\" exists\n",
    "    return tokenized_dataset\n",
    "# load training dataset\n",
    "\n",
    "\n",
    "# tokenize the datasets\n",
    "tokenized_datasets = {}\n",
    "tokenized_datasets[\"train\"] = train_dataset.map(tokenize_function, batched=True).map(add_labels)\n",
    "tokenized_datasets[\"val\"] = val_dataset.map(tokenize_function, batched=True).map(add_labels)\n",
    "tokenized_datasets[\"test\"] = test_dataset.map(tokenize_function, batched=True).map(add_labels)\n",
    "print(tokenized_datasets[\"train\"][0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu126\n",
      "12.6\n",
      "True\n",
      "1\n",
      "NVIDIA GeForce RTX 3060 Laptop GPU\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# check if GPU is available\n",
    "# ! nvidia-smi\n",
    "# ! nvcc --version\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Benny\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\Benny\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio accelerate>=0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# def train_one_epoch(model: nn.Module, dataloader: DataLoader, optimizer: Optimizer, epoch: int):\n",
    "#     model.train()\n",
    "\n",
    "#     with tqdm(dataloader, desc=f\"Train Ep {epoch}\", total=len(dataloader)) as tq:\n",
    "#         for batch in tq:\n",
    "#             # TODO: retrieve the data from your batch and send it to the same device as your model (i.e., model.device).\n",
    "#             # Hint: model.device should point to 'cuda' as you set it as such in the main function below.\n",
    "#             #       However, please use `model.device` and don't hard code it to 'cuda' as the auto-grader will put the model on CPU.\n",
    "#             # text_encoding = {key: val.to(model.device) for key, val in batch.items() if key != \"labels\"}\n",
    "#             input_ids = batch[\"text_encoding\"][\"input_ids\"].to(model.device)\n",
    "#             attention_mask = batch[\"text_encoding\"][\"attention_mask\"].to(model.device)\n",
    "#             label_encoding = batch[\"label_encoding\"].to(model.device)\n",
    "\n",
    "#             # TODO: Compute loss by running model with text_encoding and label_encoding.\n",
    "#             output = model(input_ids=input_ids, attention_mask=attention_mask, labels=label_encoding)\n",
    "#             loss = output.loss\n",
    "\n",
    "#             # TODO: compute gradients and update parameters using optimizer.\n",
    "#             # Hint: you need three lines of code here!\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             tq.set_postfix({\"loss\": loss.detach().item()}) # for printing better-looking progress bar\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)  # Convert logits to class labels\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# training\n",
    "\n",
    "learning_rate = 5e-5\n",
    "num_train_epochs = 3\n",
    "\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2)\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "training_args = TrainingArguments(\"results\", num_train_epochs=3, per_device_train_batch_size=BATCH_SIZE, per_device_eval_batch_size=BATCH_SIZE, logging_dir=\"logs\", logging_steps=10)\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=tokenized_datasets[\"train\"], eval_dataset=tokenized_datasets[\"val\"], compute_metrics=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell clears GPU memory, do this when GPU out of memory\n",
    "\n",
    "# from numba import cuda\n",
    "import gc\n",
    "gc.collect()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4/12 01:57 < 07:51, 0.02 it/s, Epoch 0.75/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
